# Expert-Level AI Development Ruleset

## Core Development Principles
```
🔄 Iterative Development:
- Start with working state analysis
- Make atomic, testable changes
- Validate each step before proceeding
- Roll back on validation failure

🧪 Test-First Development:
- Write/update tests before code changes
- Verify existing test coverage
- Run tests after each change
- Document test scenarios
```

## Classification System
🟢 Basic: Essential requirements
🟡 Advanced: Enhanced capabilities
🔴 Expert: Complex/Critical features

## Core AI Response Structure
```
📋 Technical Analysis:
- Current working state
- Dependency chain analysis
- Breaking change potential
- Test coverage impact
- Architecture impact
- Security implications
- Performance considerations
- Scalability assessment
- Contextual awareness

🔍 Implementation Details:
- Incremental changes only
- Test coverage verification
- Mock consistency check
- Integration validation
- Code changes
- Test coverage
- Security measures
- Performance optimizations
- Ethical considerations

⚠️ Risk Assessment:
- Breaking changes analysis
- Dependency conflicts
- Test environment impact
- Mock synchronization
- Security vulnerabilities
- Breaking changes
- Performance bottlenecks
- Scalability limitations
- Compliance risks
```

## Implementation Standards

### Code Quality
- Verify existing implementation
- Check dependency chain
- Validate mock consistency
- Test before implementation
- TypeScript/Python strict mode
- Comprehensive error handling
- Proper type safety
- >85% test coverage
- Security best practices

### Architecture Patterns
- Map module dependencies
- Track type relationships
- Verify mock alignment
- Test integration points
- Clean architecture principles
- Proper separation of concerns
- Scalable state management
- Efficient caching strategies
- Secure data handling

### Testing Requirements
- Pre-implementation tests
- Mock consistency checks
- Integration validation
- Dependency verification
- Unit tests (Jest/pytest)
- Integration tests (Cypress/httpx)
- Security testing
- Performance testing
- Error scenario coverage

## Documentation Requirements

### Repository History
- Track working versions
- Document dependencies
- Map type relationships
- Record test coverage
- Track architectural decisions
- Document technical evolution
- Record security/performance impacts
- Update during each conversation

### Uncommitted Changes
- Validate against tests
- Check mock consistency
- Verify dependencies
- Test integration
- Clear commit message
- Modified files with reasoning
- Technical improvements
- Validation status

### Learnings
- Document working patterns
- Track breaking changes
- Map dependencies
- Record test scenarios
- Document error patterns
- Record solutions
- Define prevention measures
- Include example patterns

## Validation Checklist
```
✅ Pre-Implementation
- [ ] Analyze working state
- [ ] Map dependencies
- [ ] Check test coverage
- [ ] Verify mocks

✅ Implementation
- [ ] Make atomic changes
- [ ] Run tests first
- [ ] Validate types
- [ ] Check integration

✅ Post-Implementation
- [ ] Verify all tests
- [ ] Check mock consistency
- [ ] Validate dependencies
- [ ] Test integration
```

## Response Template
```
📋 Analysis Complete
- Current working state verified
- Dependencies mapped
- Tests validated
- Mocks consistent

✅ Implementation Validated
- Changes are atomic
- Tests passing
- Types verified
- Integration checked

🔒 Security Confirmed
📊 Performance Verified
📝 Documentation Updated

⚠️ Follow-up Items:
1. [Required items]
2. [Suggested improvements]
```
